{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicating Logistic Regression Models by Agarwal et al. (2013) and Liu et al. (2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to try to reproduce the Logistic Regression models by Agarwal et al. (2013) and Liu et al. (2013).\n",
    "\n",
    "To achieve this we will have to complete the following steps:\n",
    "* [Done] Merge the clicked and booked items within each query as positive instances. This will turn the classification task into a binary classification task.\n",
    "* [Done] First, select a smaller feature set, consisting of the features: srch_id, prop_id, srch_destination_id, prop_starrating, prop_location_score1, prop_location_score_2, and price_usd (Liu et al., 2013). Later on, we can try to fit a model using a broader set of features.\n",
    "* [Done] Split the data into a training and an internal validation set. For this dataset, Liu et al. (2013) used a validation set that was 10% of the original data size, generated using the rule: srch_id%10==1. Agarwal et al. (2013) explained that this selection rule minimzed the correlation between searches in close proximity i.e. searches with the same search_id. \n",
    "* [Done] (Also check how many instances there are of each search id). \n",
    "* [Done] To aid in the testing phase we sample a part of the data to train the model on e.g. 10.000 points.\n",
    "* [Done] While both Agarwal et al. (2013) and Liu et al. (2013) added a class weight parameter to the cross-entropy function, we can initially try to use a balanced dataset instead. For this, we need to sample an equal number of positive and negative cases. Afterwards, we can try to fit a model with a weighted cross-entropy function as well.\n",
    "* Binarize float features e.g. using the bucket algorithm presented by Liu et al. (2013)\n",
    "* [Done] Sort the search queries based on the posterior probability of the Logistic Regression model. Here, the posterior probability serves as a measure for the relevance, directly. This approach was proposed by Agarwal et al. (2013).\n",
    "* Finally, check the performance of the model using the NDCG@38 metric. For this, it is important to check whether the evaluation metric was implemented correctly, beforehand.\n",
    "* Check out Automatic Relevance Determination Regression (ARD) (see: https://tinyurl.com/yblqaran)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure Visualization Defaults\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv('data/training_set_VU_DM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the experimental phase we select a subset of the training data\n",
    "train_sub = train.loc[0:9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check how many instances there of each search_id on a subset of the data\n",
    "# consisting of 10.000 points\n",
    "u, c = np.unique(train_sub['srch_id'], return_counts=True)\n",
    "plt.bar(u,c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure above we can see that the number of search results is not equal across search ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the feature list that we are going to use for the first model\n",
    "f_list = ['srch_id', 'prop_id', 'srch_destination_id', 'prop_starrating',\n",
    "          'prop_location_score1', 'prop_location_score2', 'price_usd',\n",
    "          'click_bool', 'booking_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features from the f_list\n",
    "train = train[f_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "srch_id                 0.000000\n",
       "prop_id                 0.000000\n",
       "srch_destination_id     0.000000\n",
       "prop_starrating         0.000000\n",
       "prop_location_score1    0.000000\n",
       "prop_location_score2    0.219902\n",
       "price_usd               0.000000\n",
       "click_bool              0.000000\n",
       "booking_bool            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the proportion of null values for each column\n",
    "train.isna().sum()/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the distribution of the prop_location_score2 data\n",
    "plt.hist(train['prop_location_score2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the above distribution shows outliers, we will use the median to impute the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values of the prop_location_score2 variable\n",
    "train['prop_location_score2'].fillna(np.nanmedian(train['prop_location_score2']),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the click and booking bools\n",
    "train['merge_bool'] = train[['click_bool','booking_bool']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the validation set\n",
    "validation = train.loc[train['srch_id']%10==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the train set does not contain the validation set\n",
    "train = train.loc[train['srch_id']%10!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  4461683\n",
      "validation:  496664\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of the train and validation sets\n",
    "print('train: ', train.shape[0])\n",
    "print('validation: ', validation.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We subsample the training data\n",
    "sub_1 = train[train['merge_bool'] == 1].sample(5000)\n",
    "sub_0 = train[train['merge_bool'] == 0].sample(5000)\n",
    "sub_even = pd.concat([sub_0, sub_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 3190909 to 2738809\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   srch_id               10000 non-null  int64  \n",
      " 1   prop_id               10000 non-null  int64  \n",
      " 2   srch_destination_id   10000 non-null  int64  \n",
      " 3   prop_starrating       10000 non-null  int64  \n",
      " 4   prop_location_score1  10000 non-null  float64\n",
      " 5   prop_location_score2  10000 non-null  float64\n",
      " 6   price_usd             10000 non-null  float64\n",
      " 7   click_bool            10000 non-null  int64  \n",
      " 8   booking_bool          10000 non-null  int64  \n",
      " 9   merge_bool            10000 non-null  int64  \n",
      "dtypes: float64(3), int64(7)\n",
      "memory usage: 859.4 KB\n"
     ]
    }
   ],
   "source": [
    "sub_even.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try to fit a Logistic Regression model, using 5 and 10-fold cross validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we import the necessary functions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we define the data and the outcome variables\n",
    "X = sub_even[['prop_starrating','prop_location_score1',\n",
    "              'prop_location_score2','price_usd']]\n",
    "y = sub_even['merge_bool']\n",
    "\n",
    "# Validation set\n",
    "X_val = validation[['prop_starrating','prop_location_score1',\n",
    "              'prop_location_score2','price_usd']]\n",
    "y_val = validation['merge_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we fit the model using 5-fold cross-validation\n",
    "clf5 = LogisticRegressionCV(cv=5).fit(X,y)\n",
    "clf10 = LogisticRegressionCV(cv=10).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV5 score : 0.5824\n",
      "CV10 score: 0.5817\n"
     ]
    }
   ],
   "source": [
    "# And show the performance of the model on the cross validated training data\n",
    "print('CV5 score :', clf5.score(X,y))\n",
    "print('CV10 score:', clf10.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV5 score : 0.6688606381779231\n",
      "CV10 score: 0.6673525763896719\n"
     ]
    }
   ],
   "source": [
    "# And show the performance of the cv models on the validation set\n",
    "print('CV5 score :', clf5.score(X_val,y_val))\n",
    "print('CV10 score:', clf10.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems we can predict the merge bool reasonably well. The next step is to sort the search queries. Agarwal et al. (2013) have proposed to use the posterior probability directly as the relevance score for a search query.\n",
    "\n",
    "After sorting, we can check whether our implementation of the evaluation metric (NDCG@38) works correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model using NDCG@38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following explanation of the evaluation metric used here, is taken directly from Agarwal et al. (2013):\n",
    "\n",
    "\"*Learning to rank methods require evaluation metrics that can account not only for class membership of the test set, but also relative ranking of the result. For our study, we use Normalized Discounted Cumulative Gain (NCDG) at position 38. NCDG is a commonly used benchmark in information retrieval [14], and was the measure used to determine the winner of the official Expedia learning to rank contest.*\n",
    "\n",
    "*NDCG is defined in terms of Discounted Cumulative Gain (DCG). For a sequence of documents $X = \\{x_1,\\dots,x_n\\}$ ranked in order of decreasing predicted relevance, and a relevance function $f(x)$, DCG at position $m < n$ is defined as:*\n",
    "\n",
    "\\begin{equation}\n",
    "DCG_m(X) = \\sum_{i=1}^m = \\frac{2^{f(x_i)}-1}{\\log_2(i+1)}\n",
    "\\end{equation}\n",
    "\n",
    "*Normalized DCG simply divides by the best possible DCG for $X$, which is desirable because different test sets may have different best-case DCGs. Hence, NDCG returns a score that falls between zero and one, with one being a perfect score - that is, one where documents display monotonically decreasing relevence scores.*\n",
    "\n",
    "*The relevance score used in our evaluation was also that provided in the official contest:*\n",
    "\n",
    "\\begin{equation}\n",
    "f(x) =\n",
    "\\begin{cases}\n",
    "5,& \\text{if hotel booked}\\\\\n",
    "1,& \\text{if hotel clicked}\\\\\n",
    "0,& \\text{otherwise}\\\\\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "*The relevance function highly rewards hotel purchases, and marginally prefers clicks over no user action.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def rel_func(clicking_bool,booking_bool):\n",
    "    if booking_bool:\n",
    "        return 5\n",
    "    if clicking_bool:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def sort_seq(sequence):\n",
    "    score_mat = np.empty([sequence.shape[0]])\n",
    "    i = 0\n",
    "    for _,s in sequence.iterrows():\n",
    "        score_mat[i] = rel_func(s['click_bool'],s['booking_bool'])\n",
    "        i += 1\n",
    "    return np.argsort(score_mat)[::-1]\n",
    "\n",
    "def dcgm38(sequence):\n",
    "    score = 0\n",
    "    i = 1\n",
    "    for _, s in sequence.iterrows():\n",
    "        score += (2**rel_func(s['click_bool'],\\\n",
    "                              s['booking_bool'])-1)/np.log2(i+1)\n",
    "        i += 1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled srch_id:  [329522 120522  64458 273813 307697 316623 211670 307664 288385 249355]\n"
     ]
    }
   ],
   "source": [
    "# We first sample all queries associated with 10 different search IDs\n",
    "n_sample = 10\n",
    "sample_srch_id = np.random.choice(np.unique(train['srch_id']),n_sample,replace=False)\n",
    "print('sampled srch_id: ', sample_srch_id)\n",
    "sample_train = pd.DataFrame()\n",
    "for i in sample_srch_id:\n",
    "    sample_train = pd.concat([sample_train,train.loc[train['srch_id']==i]])\n",
    "    \n",
    "X_sample = sample_train[['prop_starrating','prop_location_score1',\n",
    "              'prop_location_score2','price_usd']]\n",
    "y_sample = sample_train[['prop_starrating','prop_location_score1',\n",
    "              'prop_location_score2','price_usd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the queries based on the merge_bool\n",
    "Ay = pd.DataFrame()\n",
    "Ay['srch_id'] = sample_train['srch_id']\n",
    "Ay['booking_bool'] = sample_train['booking_bool']\n",
    "Ay['click_bool'] = sample_train['click_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we sort the queries using their associated posterior probabilities of a click and/or purchase\n",
    "# derived from the Logistic Regression model.\n",
    "rel_score5 = clf5.predict_proba(X_sample)\n",
    "rel_score10 = clf10.predict_proba(X_sample)\n",
    "\n",
    "A5 = pd.DataFrame()\n",
    "A5['srch_id'] = sample_train['srch_id']\n",
    "A5['booking_bool'] = sample_train['booking_bool']\n",
    "A5['click_bool'] = sample_train['click_bool']\n",
    "A5['rel_score5'] = rel_score5[:,1]\n",
    "# A5['pred'] = clf5.predict(X_sample)\n",
    "\n",
    "A10 = pd.DataFrame()\n",
    "A10['srch_id'] = sample_train['srch_id']\n",
    "A10['booking_bool'] = sample_train['booking_bool']\n",
    "A10['click_bool'] = sample_train['click_bool']\n",
    "A10['rel_score10'] = rel_score10[:,1]\n",
    "\n",
    "A5_sort = pd.DataFrame()\n",
    "A10_sort = pd.DataFrame()\n",
    "# Sort\n",
    "for i in sample_srch_id:\n",
    "    A5_sort = pd.concat([A5_sort,A5.loc[A5['srch_id']==i].sort_values(by='rel_score5',ascending=False)])\n",
    "    A10_sort = pd.concat([A10_sort,A10.loc[A10['srch_id']==i].sort_values(by='rel_score10',ascending=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG unsorted : [ 6.76123305  7.93469877 31.          0.33333333  7.93469877  9.77941118\n",
      "  0.38685281 19.55882236  1.         15.5       ]\n",
      "DCG sorted   : [31. 31. 31.  1. 31. 31.  1. 31.  1. 31.]\n",
      "mean NDCG unsorted: 0.4896601112530224\n",
      "mean NDCG sorted  : 1.0\n"
     ]
    }
   ],
   "source": [
    "dcgm = np.empty(n_sample)\n",
    "best = np.empty(n_sample)\n",
    "for i in range(n_sample):\n",
    "    dcgm[i] = dcgm38(A5_sort.loc[A5_sort['srch_id']==sample_srch_id[i]])\n",
    "    A = sort_seq(Ay.loc[Ay['srch_id']==sample_srch_id[i]])\n",
    "    best[i] = dcgm38(Ay.loc[Ay['srch_id']==sample_srch_id[i]].iloc[A])\n",
    "    \n",
    "print('DCG unsorted :', dcgm)\n",
    "print('DCG sorted   :', best)\n",
    "print('mean NDCG unsorted:', np.mean(np.divide(dcgm, best)))\n",
    "print('mean NDCG sorted  :', np.mean(np.divide(best, best)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the NDCG score of almost 0.49 seems way too high(!) so this is very likely to have been a lucky draw."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
